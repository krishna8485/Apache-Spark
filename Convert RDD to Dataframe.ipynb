{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34704124337995856,\n",
       " 0.12684987613391518,\n",
       " 0.5232218540765262,\n",
       " 0.1792035250250823,\n",
       " 0.1818773508024345,\n",
       " 0.15365752856963155,\n",
       " 0.14138991643359022,\n",
       " 0.9635876388773885,\n",
       " 0.3945759722968434,\n",
       " 0.27544104205160913]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([random() for _ in range(10)])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               col1|\n",
      "+-------------------+\n",
      "|0.02903475958679247|\n",
      "| 0.5419648099941686|\n",
      "|0.38636252396033655|\n",
      "| 0.9972304145867877|\n",
      "| 0.6614371372167224|\n",
      "|  0.554423346025148|\n",
      "| 0.6133645064469195|\n",
      "| 0.7033927741385079|\n",
      "| 0.5611481341447861|\n",
      "| 0.5114638790424043|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "rddRow = rdd.map(lambda f: Row(f))\n",
    "spark.createDataFrame(rddRow).toDF(\"col1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               col1|\n",
      "+-------------------+\n",
      "|0.02903475958679247|\n",
      "| 0.5419648099941686|\n",
      "|0.38636252396033655|\n",
      "| 0.9972304145867877|\n",
      "| 0.6614371372167224|\n",
      "|  0.554423346025148|\n",
      "| 0.6133645064469195|\n",
      "| 0.7033927741385079|\n",
      "| 0.5611481341447861|\n",
      "| 0.5114638790424043|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddRow = rdd.map(lambda f: Row(col1 = f))\n",
    "df = spark.createDataFrame(rddRow)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- c1: double (nullable = true)\n",
      " |-- c2: string (nullable = true)\n",
      " |-- c3: null (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([\n",
    "    Row(c1 = 1.0, c2 = None, c3 = None), \n",
    "    Row(c1 = None, c2= \"Apple\", c3 = None)])\n",
    "df = spark.createDataFrame(rdd, samplingRatio=1.0) # samplingRatio = 1 forces to see all records\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"c1\", FloatType()),\n",
    "    StructField(\"c2\", StringType()),\n",
    "    StructField(\"c3\", DateType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- c1: float (nullable = true)\n",
      " |-- c2: string (nullable = true)\n",
      " |-- c3: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.createDataFrame(rdd, schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+\n",
      "|  c1|   c2|  c3|\n",
      "+----+-----+----+\n",
      "| 1.0| null|null|\n",
      "|null|Apple|null|\n",
      "+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
